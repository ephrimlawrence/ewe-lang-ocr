
@article{ghosh_survey_2016,
	title = {A survey on image mosaicing techniques},
	volume = {34},
	issn = {10473203},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1047320315002059},
	doi = {10.1016/j.jvcir.2015.10.014},
	abstract = {Image mosaicing, the process of obtaining a wider ﬁeld-of-view of a scene from a sequence of partial views, has been an attractive research area because of its wide range of applications, including motion detection, resolution enhancement, monitoring global land usage, and medical imaging. A number of image mosaicing algorithms have been proposed over the last two decades. This paper provides an indepth survey of the existing image mosaicing algorithms by classifying them into several groups. For each group, the fundamental concepts are ﬁrst explained and then the modiﬁcations made to the basic concepts by different researchers are explained. Furthermore, this paper also discusses the advantages and disadvantages of all the mosaicing groups.},
	language = {en},
	urldate = {2023-04-10},
	journal = {Journal of Visual Communication and Image Representation},
	author = {Ghosh, Debabrata and Kaabouch, Naima},
	month = jan,
	year = {2016},
	pages = {1--11},
	file = {Ghosh and Kaabouch - 2016 - A survey on image mosaicing techniques.pdf:/home/ephrim/Zotero/storage/NZ2ETXIV/Ghosh and Kaabouch - 2016 - A survey on image mosaicing techniques.pdf:application/pdf},
}

@incollection{capel_image_2004,
	address = {London},
	series = {Distinguished {Dissertations}},
	title = {Image {Mosaicing}},
	isbn = {978-0-85729-384-8},
	url = {https://doi.org/10.1007/978-0-85729-384-8_4},
	abstract = {Image mosaicing is the alignment of multiple images into larger compositions which represent portions of a 3D scene. The mosaicing methods described in this chapter are concerned with images which can be registered by means of a planar homography: views of a planar scene from arbitrary viewpoints, or views of a scene taken by a rotating camera. There are three important factors to consider when constructing a mosaic: the estimation of a set of homographies which are consistent over all the views; the choice of reprojection manifold on which the images are composited; and the choice of algorithm for blending the overlapping images.},
	language = {en},
	urldate = {2023-04-10},
	booktitle = {Image {Mosaicing} and {Super}-resolution},
	publisher = {Springer},
	author = {Capel, David},
	editor = {Capel, David},
	year = {2004},
	doi = {10.1007/978-0-85729-384-8_4},
	keywords = {Interest Point, Manifold Projection, Mosaic Image, View Graph, Virtual Camera},
	pages = {47--79},
}

@incollection{wang_efficient_2012,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Electrical} {Engineering}},
	title = {Efficient {Panorama} {Mosaicing} {Based} on {Enhanced}-{FAST} and {Graph} {Cuts}},
	isbn = {978-3-642-25792-6},
	url = {https://doi.org/10.1007/978-3-642-25792-6_115},
	abstract = {This paper presents an efficient and accurate method for creating full view panoramas. A new feature points detection algorithm called Enhanced- FAST is proposed to accurately align images and a graph cuts algorithm is used to merge two adjacent images seamlessly. Based on the FAST algorithm, the Enhanced-FAST algorithm smoothes and extends the sampling area making the feature points detection more insensitive to noise. Our graph cuts algorithm uses image Laplacian to compute the edge weights which can find an optimized seam even under different lighting. Experiments and comparisons show that our method is efficient and robust to image noise and lighting changing},
	language = {en},
	urldate = {2023-04-11},
	booktitle = {Recent {Advances} in {Computer} {Science} and {Information} {Engineering}: {Volume} 5},
	publisher = {Springer},
	author = {Wang, Xun and Sun, Jie and Peng, Hao-Yu},
	editor = {Qian, Zhihong and Cao, Lei and Su, Weilian and Wang, Tingkai and Yang, Huamin},
	year = {2012},
	doi = {10.1007/978-3-642-25792-6_115},
	keywords = {feature detection, graph cuts, image alignment, panorama},
	pages = {757--762},
	file = {Wang et al. - 2012 - Efficient Panorama Mosaicing Based on Enhanced-FAS.pdf:/home/ephrim/Zotero/storage/LVW4YM87/Wang et al. - 2012 - Efficient Panorama Mosaicing Based on Enhanced-FAS.pdf:application/pdf},
}

@inproceedings{davison_real-time_2003,
	title = {Real-time simultaneous localisation and mapping with a single camera},
	doi = {10.1109/ICCV.2003.1238654},
	abstract = {Ego-motion estimation for an agile single camera moving through general, unknown scenes becomes a much more challenging problem when real-time performance is required rather than under the off-line processing conditions under which most successful structure from motion work has been achieved. This task of estimating camera motion from measurements of a continuously expanding set of self-mapped visual features is one of a class of problems known as Simultaneous Localisation and Mapping (SLAM) in the robotics community, and we argue that such real-time mapping research, despite rarely being camera-based, is more relevant here than off-line structure from motion methods due to the more fundamental emphasis placed on propagation of uncertainty. We present a top-down Bayesian framework for single-camera localisation via mapping of a sparse set of natural features using motion modelling and an information-guided active measurement strategy, in particular addressing the difficult issue of real-time feature initialisation via a factored sampling approach. Real-time handling of uncertainty permits robust localisation via the creating and active measurement of a sparse map of landmarks such that regions can be re-visited after periods of neglect and localisation can continue through periods when few features are visible. Results are presented of real-time localisation for a hand-waved camera with very sparse prior scene knowledge and all processing carried out on a desktop PC.},
	booktitle = {Proceedings {Ninth} {IEEE} {International} {Conference} on {Computer} {Vision}},
	author = {{Davison}},
	month = oct,
	year = {2003},
	keywords = {Bayesian methods, Cameras, Layout, Motion estimation, Motion measurement, Particle measurements, Robot vision systems, Robustness, Sampling methods, Simultaneous localization and mapping},
	pages = {1403--1410 vol.2},
	file = {IEEE Xplore Abstract Record:/home/ephrim/Zotero/storage/6LAP7GBP/stamp.html:text/html;IEEE Xplore Full Text PDF:/home/ephrim/Zotero/storage/JJ2HCQBA/Davison - 2003 - Real-time simultaneous localisation and mapping wi.pdf:application/pdf},
}

@inproceedings{viswanathan_features_2009,
	title = {Features from accelerated segment test (fast)},
	booktitle = {Proceedings of the 10th workshop on image analysis for multimedia interactive services, {London}, {UK}},
	author = {Viswanathan, Deepak Geetha},
	year = {2009},
	pages = {6--8},
	file = {Full Text:/home/ephrim/Zotero/storage/E539ABV3/Viswanathan - 2009 - Features from accelerated segment test (fast).pdf:application/pdf},
}

@inproceedings{yu_real-time_2010,
	address = {Aberystwyth},
	title = {Real-time {Action} {Recognition} by {Spatiotemporal} {Semantic} and {Structural} {Forests}},
	isbn = {978-1-901725-40-7},
	url = {http://www.bmva.org/bmvc/2010/conference/paper52/index.html},
	doi = {10.5244/C.24.52},
	abstract = {Whereas most existing action recognition methods require computationally demanding feature extraction and/or classiﬁcation, this paper presents a novel real-time solution that utilises local appearance and structural information. Semantic texton forests (STFs) are applied to local space-time volumes as a powerful discriminative codebook. Since STFs act directly on video pixels without using expensive descriptors, visual codeword generation by STFs is extremely fast. To capture the structural information of actions, so called pyramidal spatiotemporal relationship match (PSRM) is introduced. Leveraging the hierarchical structure of STFs, the pyramid match kernel is applied to obtain robust structural matching, avoiding quantisation effects. We propose the kernel k-means forest classiﬁer using PSRM to perform classiﬁcation. In the experiments using KTH and the latest UT-interaction data sets, we demonstrate real-time performance as well as state-ofthe-art accuracy by the proposed method.},
	language = {en},
	urldate = {2023-04-16},
	booktitle = {Procedings of the {British} {Machine} {Vision} {Conference} 2010},
	publisher = {British Machine Vision Association},
	author = {Yu, Tsz-Ho and Kim, Tae-Kyun and Cipolla, Roberto},
	year = {2010},
	pages = {52.1--52.12},
	file = {Yu et al. - 2010 - Real-time Action Recognition by Spatiotemporal Sem.pdf:/home/ephrim/Zotero/storage/SPBHRLC6/Yu et al. - 2010 - Real-time Action Recognition by Spatiotemporal Sem.pdf:application/pdf},
}

@article{shum_systems_2000,
	title = {Systems and experiment paper: {Construction} of panoramic image mosaics with global and local alignment},
	volume = {36},
	shorttitle = {Systems and experiment paper},
	journal = {International Journal of Computer Vision},
	author = {Shum, Heung-Yeung and Szeliski, Richard},
	year = {2000},
	note = {Publisher: Springer},
	pages = {101--130},
	file = {Full Text:/home/ephrim/Zotero/storage/A42WZTA5/Shum and Szeliski - 2000 - Systems and experiment paper Construction of pano.pdf:application/pdf;Snapshot:/home/ephrim/Zotero/storage/VW237J56/a1008195814169.html:text/html},
}

@article{wei_image_2020,
	title = {Image {Redundancy} {Filtering} for {Panorama} {Stitching}},
	volume = {8},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2020.3038178},
	abstract = {In this paper, we designed a novel framework for massive image panorama stitching, which aims to resolve image redundancy, alignment error accumulation and perspective distortion accumulation of the stitching process. First, an iterative method is designed to filter the redundancy images by analysing the similarity relation of adjacent images. Second, to reduce alignment error accumulation, the weight topology graph of filtered images is constructed, which is employed to find the optimal reference image which closes to the central geometrically by the Floyd-Warshall algorithm. Finally, a two-step global alignment strategy is designed to initial align images and perform shape optimization, the first step is that filtered images employ the similarity model to roughly align group by group, the second step is to perform shape optimization further through refining all alignment parameters by the homography model under the anti-perspective energy term, which aims to obtain an optimal solution by balancing the alignment accuracy and the global consistency. Compared with the state-of-the-art methods, the proposed method successfully reduces image redundancy while improving the alignment and reducing perspective distortion for massive image panorama stitching.},
	journal = {IEEE Access},
	author = {Wei, Xin and Yan, Weiqing and Zheng, Qiang and Gu, Meiqi and Su, Kaiqi and Yue, Guanghui and Liu, Yun},
	year = {2020},
	note = {Conference Name: IEEE Access},
	keywords = {Image edge detection, Filtering, Cost function, global consistency, Image stitching, Mathematical model, Nonlinear distortion, Redundancy, redundancy image, Topology, topology estimation},
	pages = {209113--209126},
	file = {IEEE Xplore Abstract Record:/home/ephrim/Zotero/storage/YDJ2X54B/stamp.html:text/html;IEEE Xplore Full Text PDF:/home/ephrim/Zotero/storage/QQ64VSH7/Wei et al. - 2020 - Image Redundancy Filtering for Panorama Stitching.pdf:application/pdf},
}

@article{lyu_survey_2019,
	title = {A survey on image and video stitching},
	volume = {1},
	issn = {2096-5796},
	url = {https://www.sciencedirect.com/science/article/pii/S2096579619300063},
	doi = {10.3724/SP.J.2096-5796.2018.0008},
	abstract = {Image/video stitching is a technology for solving the field of view (FOV) limitation of images/ videos. It stitches multiple overlapping images/videos to generate a wide-FOV image/video, and has been used in various fields such as sports broadcasting, video surveillance, street view, and entertainment. This survey reviews image/video stitching algorithms, with a particular focus on those developed in recent years. Image stitching first calculates the corresponding relationships between multiple overlapping images, deforms and aligns the matched images, and then blends the aligned images to generate a wide-FOV image. A seamless method is always adopted to eliminate such potential flaws as ghosting and blurring caused by parallax or objects moving across the overlapping regions. Video stitching is the further extension of image stitching. It usually stitches selected frames of original videos to generate a stitching template by performing image stitching algorithms, and the subsequent frames can then be stitched according to the template. Video stitching is more complicated with moving objects or violent camera movement, because these factors introduce jitter, shakiness, ghosting, and blurring. Foreground detection technique is usually combined into stitching to eliminate ghosting and blurring, while video stabilization algorithms are adopted to solve the jitter and shakiness. This paper further discusses panoramic stitching as a special-extension of image / video stitching. Panoramic stitching is currently the most widely used application in stitching. This survey reviews the latest image/video stitching methods, and introduces the fundamental principles/advantages/weaknesses of image/video stitching algorithms. Image/video stitching faces long-term challenges such as wide baseline, large parallax, and low-texture problem in the overlapping region. New technologies may present new opportunities to address these issues, such as deep learning-based semantic correspondence, and 3D image stitching. Finally, this survey discusses the challenges of image/video stitching and proposes potential solutions.},
	language = {en},
	number = {1},
	urldate = {2023-04-18},
	journal = {Virtual Reality \& Intelligent Hardware},
	author = {Lyu, Wei and Zhou, Zhong and Chen, Lang and Zhou, Yi},
	month = feb,
	year = {2019},
	keywords = {Image stitching, 3D stitching, Alignment, Deep learning, Mesh optimization, Panoramic stitching, Registration, Video stitching},
	pages = {55--83},
	file = {ScienceDirect Full Text PDF:/home/ephrim/Zotero/storage/XP9YJUKG/Lyu et al. - 2019 - A survey on image and video stitching.pdf:application/pdf;ScienceDirect Snapshot:/home/ephrim/Zotero/storage/IWUKS2KD/S2096579619300063.html:text/html},
}

@inproceedings{alvaro_basic_2010,
	title = {Basic handwriting instructor for kids using {OCR} as an {Evaluator}},
	doi = {10.1109/ICNIT.2010.5508516},
	abstract = {Writing is a skill that is used in all academic coursework as well as through a person's professional and personal life. Technology has become an influential factor when it comes to education. Computers are used in developed countries to complement established education practices and develop new ways of learning. Computer Aided Instruction (CAI) helps us to make the present teaching learning process easy to understand through audio-visual aids. In this study, the proponents developed a software application that will teach children ages 4–6 how to write by using stylus and be able to write on the touch screen monitor of the computer. The basic handwriting software for kids show images containing steps on how to write the alphabet and audio sounds to identify what letter should be written. Children can trace letters using tablet or touch screen devices and will be evaluated afterwards using Optical Character Recognition (OCR). A survey is conducted using a questionnaire for both professional school teachers and parents. Results proved that the software contains activities and lessons that are appropriate to the comprehension level of children. It also showed that the software provided children with user friendly, functional, reliable and correct alternative way of teaching basic handwriting.},
	booktitle = {2010 {International} {Conference} on {Networking} and {Information} {Technology}},
	author = {Alvaro, Alvin Kenneth S. and Dela Cruz, Rowan Larch D.J. and Fonseca, Donn Mark T. and Samonte, Mary Jane C.},
	month = jun,
	year = {2010},
	note = {ISSN: 2324-8203},
	keywords = {Educational institutions, Application software, Character recognition, computer aided instruction, Computer aided instruction, Computer science education, Computerized monitoring, Educational technology, Optical character recognition software, Optical devices, touch screen, writing, Writing},
	pages = {265--268},
	file = {IEEE Xplore Abstract Record:/home/ephrim/Zotero/storage/8HUY929B/5508516.html:text/html},
}

@inproceedings{mombach_mirrored_2020,
	title = {Mirrored and {Rotated} {Letters} in {Children} {Spellings}: {An} {Automatic} {Analysis} {Approach}},
	shorttitle = {Mirrored and {Rotated} {Letters} in {Children} {Spellings}},
	doi = {10.1109/CCECE47787.2020.9255765},
	abstract = {Spelling tests for children are a typical activity in primary schools and clinics specialized in child development. Commonly, some child's letters can be mirrored or rotated, and Optical Character Systems (OCRs) do not recognize nonstandard letters. Consequently, automatic evaluation approaches are harmed in this context. Furthermore, depending on the child's age, identifying mirrored or rotated letters can support earlier diagnoses of learning disabilities, such as dyslexia or dysgraphia. Therefore, we propose a method for identifying the occurrence of mirrored and rotated letters in children's spellings. The approach uses image processing techniques to extract letters from paper tests and performs transformations so it can be recognized automatically. Preliminary results indicate a promising approach, reaching an accuracy of 96\% for mirrored letters recognition and 98\% in rotated letters.},
	booktitle = {2020 {IEEE} {Canadian} {Conference} on {Electrical} and {Computer} {Engineering} ({CCECE})},
	author = {Mombach, Jaline and Ferreira, Cristiane and Felix, Juliana and Salvini, Rogerio and Soares, Fabrizzio},
	month = aug,
	year = {2020},
	note = {ISSN: 2576-7046},
	keywords = {Image segmentation, Gray-scale, Optical character recognition software, Writing, Children, Handwriting, Mirrors, Pediatrics, Proposals, Spelling Test},
	pages = {1--4},
	file = {IEEE Xplore Abstract Record:/home/ephrim/Zotero/storage/G6DAMH5M/9255765.html:text/html},
}

@article{zin_handwritten_2021,
	title = {Handwritten {Character} {Recognition} on {Android} for {Basic} {Education} {Using} {Convolutional} {Neural} {Network}},
	volume = {10},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2079-9292},
	url = {https://www.mdpi.com/2079-9292/10/8/904},
	doi = {10.3390/electronics10080904},
	abstract = {An international initiative called Education for All (EFA) aims to create an environment in which everyone in the world can get an education. Especially in developing countries, many children lack access to a quality education. Therefore, we propose an offline self-learning application to learn written English and basic calculation for primary level students. It can also be used as a supplement for teachers to make the learning environment more interactive and interesting. In our proposed system, handwritten characters or words written on tablets were saved as input images. Then, we performed character segmentation by using our proposed character segmentation methods. For the character recognition, the Convolutional Neural Network (CNN) was used for recognizing segmented characters. For building our own dataset, handwritten data were collected from primary level students in developing countries. The network model was trained on a high-end machine to reduce the workload on the Android tablet. Various types of classifiers (digit and special characters, uppercase letters, lowercase letters, etc.) were created in order to reduce the incorrect classification. According to our experimental results, the proposed system achieved 95.6\% on the 1000 randomly selected words and 98.7\% for each character.},
	language = {en},
	number = {8},
	urldate = {2023-04-30},
	journal = {Electronics},
	author = {Zin, Thi Thi and Thant, Shin and Pwint, Moe Zet and Ogino, Tsugunobu},
	month = jan,
	year = {2021},
	note = {Number: 8
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {basic educational application, closed character detection, Convolutional Neural Network, cursive character recognition, handwritten character recognition, offline self-learning application, projection},
	pages = {904},
	file = {Full Text PDF:/home/ephrim/Zotero/storage/4QELUD67/Zin et al. - 2021 - Handwritten Character Recognition on Android for B.pdf:application/pdf},
}

@article{berninger_writing_2002,
	title = {Writing and {Reading}: {Connections} {Between} {Language} by {Hand} and {Language} by {Eye}},
	volume = {35},
	issn = {0022-2194, 1538-4780},
	shorttitle = {Writing and {Reading}},
	url = {http://journals.sagepub.com/doi/10.1177/002221940203500104},
	doi = {10.1177/002221940203500104},
	abstract = {Four approaches to the investigation of connections between language by hand and language by eye are described and illustrated with studies from a decade-long research program. In the first approach, multigroup structural equation modeling is applied to reading and writing measures given to typically developing writers to examine unidirectional and bidirectional relationships between specific components of the reading and writing systems. In the second approach, structural equation modeling is applied to a multivariate set of language measures given to children and adults with reading and writing disabilities to examine how the same set of language processes is orchestrated differently to accomplish specific reading or writing goals, and correlations between factors are evaluated to examine the level at which the language-by-hand system and the language-by-eye system communicate most easily. In the third approach, mode of instruction and mode of response are systematically varied in evaluating effectiveness of treating reading disability with and without a writing component. In the fourth approach, functional brain imaging is used to investigate residual spelling problems in students whose problems with word decoding have been remediated. The four approaches support a model in which language by hand and language by eye are separate systems that interact in predictable ways.},
	language = {en},
	number = {1},
	urldate = {2023-04-30},
	journal = {Journal of Learning Disabilities},
	author = {Berninger, Virginia W. and Abbott, Robert D. and Abbott, Sylvia P. and Graham, Steve and Richards, Todd},
	month = jan,
	year = {2002},
	pages = {39--56},
	file = {Berninger et al. - 2002 - Writing and Reading Connections Between Language .pdf:/home/ephrim/Zotero/storage/BP84BAN5/Berninger et al. - 2002 - Writing and Reading Connections Between Language .pdf:application/pdf},
}

@article{longcamp_remembering_2006,
	series = {Advances in {Graphonomics}: {Studies} on {Fine} {Motor} {Control}, {Its} {Development} and {Disorders}},
	title = {Remembering the orientation of newly learned characters depends on the associated writing knowledge: {A} comparison between handwriting and typing},
	volume = {25},
	issn = {0167-9457},
	shorttitle = {Remembering the orientation of newly learned characters depends on the associated writing knowledge},
	url = {https://www.sciencedirect.com/science/article/pii/S0167945706000649},
	doi = {10.1016/j.humov.2006.07.007},
	abstract = {Recent data support the idea that movements play a crucial role in letter representation and suggest that handwriting knowledge contributes to visual recognition of letters. If so, using different motor activities while subjects are learning to write should affect their subsequent recognition performances. In order to test this hypothesis, we trained adult participants to write new characters either by copying them or by typing them on a keyboard. After three weeks of training we ran a series of tests requiring visual processing of the characters’ orientation. Tests were ran immediately, one week after, and three weeks after the end of the training period. Results showed that when the characters had been learned by typing, they were more frequently confused with their mirror images than when they had been written by hand. This handwriting advantage did not appear immediately, but mostly three weeks after the end of the training. Our results therefore suggest that the stability of the characters’ representation in memory depends on the nature of the motor activity produced during learning.},
	language = {en},
	number = {4},
	urldate = {2023-04-30},
	journal = {Human Movement Science},
	author = {Longcamp, Marieke and Boucard, Céline and Gilhodes, Jean-Claude and Velay, Jean-Luc},
	month = oct,
	year = {2006},
	keywords = {Handwriting, Learning, Letter recognition, Motor–perceptual interactions, Typing},
	pages = {646--656},
	file = {ScienceDirect Snapshot:/home/ephrim/Zotero/storage/YYDBABGF/S0167945706000649.html:text/html},
}

@article{dinehart_associations_2013,
	title = {Associations {Between} {Low}-{Income} {Children}'s {Fine} {Motor} {Skills} in {Preschool} and {Academic} {Performance} in {Second} {Grade}},
	volume = {24},
	issn = {1040-9289},
	url = {https://doi.org/10.1080/10409289.2011.636729},
	doi = {10.1080/10409289.2011.636729},
	abstract = {Research Findings: Given the growing literature pertaining to the importance of fine motor skills for later academic achievement (D. W. Grissmer, K. J. Grimm, S. M. Aiyer, W. M. Murrah, \& J. S. Steele, 2010), the current study examines whether the fine motor skills of economically disadvantaged preschool students predict later academic performance in 2nd grade. More specifically, we expand on the current literature and evaluate whether 2 types of fine motor skills—fine motor object manipulation and fine motor writing—predict academic achievement above and beyond the effects of demographic characteristics and early language and cognition skills. Results indicate that performance on both fine motor writing and object manipulation tasks had significant effects on 2nd-grade reading and math achievement, as measured by grades and standardized test scores. Stronger effects were yielded for writing tasks compared to object manipulation tasks. Practice or Policy: Implications for researchers and early childhood practitioners are discussed.},
	number = {2},
	urldate = {2023-04-30},
	journal = {Early Education and Development},
	author = {Dinehart, Laura and Manfra, Louis},
	month = feb,
	year = {2013},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/10409289.2011.636729},
	pages = {138--161},
}

@article{longcamp_influence_2005,
	title = {The influence of writing practice on letter recognition in preschool children: a comparison between handwriting and typing},
	volume = {119},
	issn = {0001-6918},
	shorttitle = {The influence of writing practice on letter recognition in preschool children},
	doi = {10.1016/j.actpsy.2004.10.019},
	abstract = {A large body of data supports the view that movement plays a crucial role in letter representation and suggests that handwriting contributes to the visual recognition of letters. If so, changing the motor conditions while children are learning to write by using a method based on typing instead of handwriting should affect their subsequent letter recognition performances. In order to test this hypothesis, we trained two groups of 38 children (aged 3-5 years) to copy letters of the alphabet either by hand or by typing them. After three weeks of learning, we ran two recognition tests, one week apart, to compare the letter recognition performances of the two groups. The results showed that in the older children, the handwriting training gave rise to a better letter recognition than the typing training.},
	language = {eng},
	number = {1},
	journal = {Acta Psychologica},
	author = {Longcamp, Marieke and Zerbato-Poudou, Marie-Thérèse and Velay, Jean-Luc},
	month = may,
	year = {2005},
	pmid = {15823243},
	keywords = {Humans, Handwriting, Child, Preschool, Female, Functional Laterality, Linguistics, Male, Motor Skills, Psychomotor Performance, Recognition, Psychology},
	pages = {67--79},
}

@inproceedings{smith_overview_2007,
	address = {Curitiba, Parana, Brazil},
	title = {An {Overview} of the {Tesseract} {OCR} {Engine}},
	isbn = {978-0-7695-2822-9},
	url = {http://ieeexplore.ieee.org/document/4376991/},
	doi = {10.1109/ICDAR.2007.4376991},
	abstract = {The Tesseract OCR engine, as was the HP Research Prototype in the UNLV Fourth Annual Test of OCR Accuracy[1], is described in a comprehensive overview. Emphasis is placed on aspects that are novel or at least unusual in an OCR engine, including in particular the line finding, features/classification methods, and the adaptive classifier.},
	language = {en},
	urldate = {2023-04-30},
	booktitle = {Ninth {International} {Conference} on {Document} {Analysis} and {Recognition} ({ICDAR} 2007) {Vol} 2},
	publisher = {IEEE},
	author = {Smith, R.},
	month = sep,
	year = {2007},
	note = {ISSN: 1520-5363},
	pages = {629--633},
	file = {Smith - 2007 - An Overview of the Tesseract OCR Engine.pdf:/home/ephrim/Zotero/storage/7RWZF5Y9/Smith - 2007 - An Overview of the Tesseract OCR Engine.pdf:application/pdf},
}

@article{faizullah_survey_2023,
	title = {A {Survey} of {OCR} in {Arabic} {Language}: {Applications}, {Techniques}, and {Challenges}},
	volume = {13},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	shorttitle = {A {Survey} of {OCR} in {Arabic} {Language}},
	url = {https://www.mdpi.com/2076-3417/13/7/4584},
	doi = {10.3390/app13074584},
	abstract = {Optical character recognition (OCR) is the process of extracting handwritten or printed text from a scanned or printed image and converting it to a machine-readable form for further data processing, such as searching or editing. Automatic text extraction using OCR helps to digitize documents for improved productivity and accessibility and for preservation of historical documents. This paper provides a survey of the current state-of-the-art applications, techniques, and challenges in Arabic OCR. We present the existing methods for each step of the complete OCR process to identify the best-performing approach for improved results. This paper follows the keyword-search method for reviewing the articles related to Arabic OCR, including the backward and forward citations of the article. In addition to state-of-art techniques, this paper identifies research gaps and presents future directions for Arabic OCR.},
	language = {en},
	number = {7},
	urldate = {2023-04-30},
	journal = {Applied Sciences},
	author = {Faizullah, Safiullah and Ayub, Muhammad Sohaib and Hussain, Sajid and Khan, Muhammad Asad},
	month = jan,
	year = {2023},
	note = {Number: 7
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {Arabic OCR, classification, optical character recognition, postprocessing, preprocessing, segmentation},
	pages = {4584},
}

@inproceedings{tang_web-based_2006,
	title = {A {Web}-{Based} {Chinese} {Handwriting} {Education} {System} with {Automatic} {Feedback} and {Analysis}},
	isbn = {978-3-540-49027-2},
	doi = {10.1007/11925293_17},
	abstract = {We propose a web-based Chinese handwriting system that allows students to learn Chinese handwriting at anytime and anywhere.
The system combines technologies such as electronic ink, database, Flash animations, and pattern recognition technique to
provide students with an intelligent and effective learning environment. In particular, our system contains an Automatic Feedback
and Analysis (AFA) tool that can check multiple kinds of handwriting mistakes and provide useful feedback to the user. Survey
results show that most users agreed that our proposed system can help them to learn Chinese handwriting more efficiently as
well as reducing teachers’ workload. The user evaluation results suggest that it takes less time for users to learn Chinese
handwriting with our system than with traditional teaching method.},
	author = {Tang, Kai-Tai and Li, Ka-Ki and Leung, Howard},
	month = jul,
	year = {2006},
	pages = {176--188},
}

@inproceedings{ye_document_2013,
	title = {Document {Image} {Quality} {Assessment}: {A} {Brief} {Survey}},
	shorttitle = {Document {Image} {Quality} {Assessment}},
	doi = {10.1109/ICDAR.2013.148},
	abstract = {To maintain, control and enhance the quality of document images and minimize the negative impact of degradations on various analysis and processing systems, it is critical to understand the types and sources of degradations and develop reliable methods for estimating the levels of degradations. This paper provides a brief survey of research on the topic of document image quality assessment. We first present a detailed analysis of the types and sources of document degradations. We then review techniques for document image degradation modeling. Finally, we discuss objective measures and subjective experiments that are used to characterize document image quality.},
	booktitle = {2013 12th {International} {Conference} on {Document} {Analysis} and {Recognition}},
	author = {Ye, Peng and Doermann, David},
	month = aug,
	year = {2013},
	note = {ISSN: 2379-2140},
	keywords = {Measurement, Noise, Accuracy, Optical character recognition software, Degradation, Entropy, Image quality, image quality assessment},
	pages = {723--727},
	file = {IEEE Xplore Abstract Record:/home/ephrim/Zotero/storage/AQFUS2YK/6628713.html:text/html;IEEE Xplore Full Text PDF:/home/ephrim/Zotero/storage/IWSE4GKX/Ye and Doermann - 2013 - Document Image Quality Assessment A Brief Survey.pdf:application/pdf},
}

@inproceedings{asad_high_2016,
	title = {High {Performance} {OCR} for {Camera}-{Captured} {Blurred} {Documents} with {LSTM} {Networks}},
	doi = {10.1109/DAS.2016.69},
	abstract = {Documents are routinely captured by digital cameras in today's age owing to the availability of high quality cameras in smart phones. However, recognition of camera-captured documents is substantially more challenging as compared to traditional flat bed scanned documents due to the distortions introduced by the cameras. One of the major performancelimiting artifacts is the motion and out-of-focus blur that is often induced in the document during the capturing process. Existing approaches try to detect presence of blur in the document to inform the user for re-capturing the image. This paper reports, for the first time, an Optical Character Recognition (OCR) system that can directly recognize blurred documents on which the stateof-the-art OCR systems are unable to provide usable results. Our presented system is based on the Long Short-Term Memory (LSTM) networks and has shown promising character recognition results on both the motion-blurred and out-of-focus blurred images. One important feature of this work is that the LSTM networks have been applied directly to the gray-scale document images to avoid error-prone binarization of blurred documents. Experiments are conducted on publicly available SmartDoc-QA dataset that contains a wide variety of image blur degradations. Our presented system achieves 12.3\% character error rate on the test documents, which is an over three-fold reduction in the error rate (38.9\%) of the best-performing contemporary OCR system (ABBYY Fine Reader) on the same data.},
	booktitle = {2016 12th {IAPR} {Workshop} on {Document} {Analysis} {Systems} ({DAS})},
	author = {Asad, Fallak and Ul-Hasan, Adnan and Shafait, Faisal and Dengel, Andreas},
	month = apr,
	year = {2016},
	keywords = {Feature extraction, Training, Character recognition, Optical character recognition software, optical character recognition, blur, Blurred document, Computer architecture, Distortion, Hidden Markov models, LSTM Networks, motion blur, OCR, out of focus blur},
	pages = {7--12},
	file = {IEEE Xplore Abstract Record:/home/ephrim/Zotero/storage/ZBDQPTGN/7490085.html:text/html;IEEE Xplore Full Text PDF:/home/ephrim/Zotero/storage/JR99KDYN/Asad et al. - 2016 - High Performance OCR for Camera-Captured Blurred D.pdf:application/pdf},
}

@article{faizullah_survey_2023-1,
	title = {A {Survey} of {OCR} in {Arabic} {Language}: {Applications}, {Techniques}, and {Challenges}},
	volume = {13},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	shorttitle = {A {Survey} of {OCR} in {Arabic} {Language}},
	url = {https://www.mdpi.com/2076-3417/13/7/4584},
	doi = {10.3390/app13074584},
	abstract = {Optical character recognition (OCR) is the process of extracting handwritten or printed text from a scanned or printed image and converting it to a machine-readable form for further data processing, such as searching or editing. Automatic text extraction using OCR helps to digitize documents for improved productivity and accessibility and for preservation of historical documents. This paper provides a survey of the current state-of-the-art applications, techniques, and challenges in Arabic OCR. We present the existing methods for each step of the complete OCR process to identify the best-performing approach for improved results. This paper follows the keyword-search method for reviewing the articles related to Arabic OCR, including the backward and forward citations of the article. In addition to state-of-art techniques, this paper identifies research gaps and presents future directions for Arabic OCR.},
	language = {en},
	number = {7},
	urldate = {2023-04-30},
	journal = {Applied Sciences},
	author = {Faizullah, Safiullah and Ayub, Muhammad Sohaib and Hussain, Sajid and Khan, Muhammad Asad},
	month = jan,
	year = {2023},
	note = {Number: 7
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {Arabic OCR, classification, optical character recognition, postprocessing, preprocessing, segmentation},
	pages = {4584},
	file = {Full Text PDF:/home/ephrim/Zotero/storage/HLTZ4AZR/Faizullah et al. - 2023 - A Survey of OCR in Arabic Language Applications, .pdf:application/pdf},
}

@misc{noauthor_konvajs_2023,
	title = {Konva.js},
	url = {https://konvajs.org/index.html},
	abstract = {Konva is 2d Canvas JavaScript framework for drawings shapes, animations, node nesting, layering, filtering, event handling, drag and drop and much more.},
	language = {en},
	urldate = {2023-05-01},
	journal = {Konva.js - JavaScript 2d canvas library},
	month = apr,
	year = {2023},
	file = {Snapshot:/home/ephrim/Zotero/storage/PMI37R94/konvajs.org.html:text/html},
}

@misc{noauthor_react_2023,
	title = {React},
	url = {https://react.dev/},
	abstract = {The library for web and native user interfaces},
	language = {en},
	urldate = {2023-05-01},
	year = {2023},
	file = {Snapshot:/home/ephrim/Zotero/storage/E9A2KGJZ/react.dev.html:text/html},
}

@article{bangare_reviewing_2015,
	title = {Reviewing {Otsu}’s {Method} {For} {Image} {Thresholding}},
	volume = {10},
	issn = {0973-4562, 0973-9769},
	url = {http://ripublication.com/ijaerdoi/2015/ijaerv10n9_20.pdf},
	doi = {10.37622/IJAER/10.9.2015.21777-21783},
	abstract = {Image processing is largely used for gathering more knowledge / understanding either by human or by machines like computer. Segmentation, Thresholding and Edge detection are an important technique in Computer vision and Image processing. In digital images feature detection or extraction can be done for finding the irregularities in the image maybe in the rightness etc. This paper is a small review on Otsu‟s method. This is proposed for improving the efficiency of computation for the optimal thresholds of an image.},
	language = {en},
	number = {9},
	urldate = {2023-05-01},
	journal = {International Journal of Applied Engineering Research},
	author = {Bangare, Sunil L. and Dubal, Amruta and Bangare, Pallavi S. and Patil, S.T.},
	month = may,
	year = {2015},
	pages = {21777--21783},
	file = {Bangare et al. - 2015 - Reviewing Otsu’s Method For Image Thresholding.pdf:/home/ephrim/Zotero/storage/ME5CMEHK/Bangare et al. - 2015 - Reviewing Otsu’s Method For Image Thresholding.pdf:application/pdf},
}

@misc{noauthor_improving_nodate,
	title = {Improving the quality of the output},
	url = {https://tesseract-ocr.github.io/tessdoc/ImproveQuality.html},
	abstract = {Tesseract documentation},
	language = {en-US},
	urldate = {2023-05-01},
	journal = {tessdoc},
	file = {Snapshot:/home/ephrim/Zotero/storage/9KE96G4C/ImproveQuality.html:text/html},
}

@article{sporici_improving_2020,
	title = {Improving the {Accuracy} of {Tesseract} 4.0 {OCR} {Engine} {Using} {Convolution}-{Based} {Preprocessing}},
	volume = {12},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2073-8994},
	url = {https://www.mdpi.com/2073-8994/12/5/715},
	doi = {10.3390/sym12050715},
	abstract = {Optical Character Recognition (OCR) is the process of identifying and converting texts rendered in images using pixels to a more computer-friendly representation. The presented work aims to prove that the accuracy of the Tesseract 4.0 OCR engine can be further enhanced by employing convolution-based preprocessing using specific kernels. As Tesseract 4.0 has proven great performance when evaluated against a favorable input, its capability of properly detecting and identifying characters in more realistic, unfriendly images is questioned. The article proposes an adaptive image preprocessing step guided by a reinforcement learning model, which attempts to minimize the edit distance between the recognized text and the ground truth. It is shown that this approach can boost the character-level accuracy of Tesseract 4.0 from 0.134 to 0.616 (+359\% relative change) and the F1 score from 0.163 to 0.729 (+347\% relative change) on a dataset that is considered challenging by its authors.},
	language = {en},
	number = {5},
	urldate = {2023-05-01},
	journal = {Symmetry},
	author = {Sporici, Dan and Cușnir, Elena and Boiangiu, Costin-Anton},
	month = may,
	year = {2020},
	note = {Number: 5
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {optical character recognition, actor-critic model, convolution, convolutional neural network, reinforcement learning, tesseract, unsupervised learning},
	pages = {715},
	file = {Full Text PDF:/home/ephrim/Zotero/storage/N7KZ9N72/Sporici et al. - 2020 - Improving the Accuracy of Tesseract 4.0 OCR Engine.pdf:application/pdf},
}

@article{hengaju_improving_2023,
	title = {Improving the {Recognition} {Accuracy} of {Tesseract}-{OCR} {Engine} on {Nepali} {Text} {Images} via {Preprocessing}},
	volume = {3},
	copyright = {Copyright (c) 2020 Umesh Hengaju},
	url = {http://hbrppublication.com/OJS/index.php/AIPPR/article/view/1639},
	abstract = {Image Documents scanned or captured by digital cameras on mobile phones suffer from a number of limitations like geometric distortions, focus loss, uneven lightning conditions, low scanning resolution etc. Because of these limitations, the quality of image documents is often degraded and because of this, the recognition accuracy of OCR engines gets affected. This work focuses on improving the recognition of Tesseract-OCR engine for Nepali image documents via preprocessing. For this purpose, we developed an image preprocessing pipeline consisting of 8 steps and tested with several Nepali text images which were collected from different sources like Nepali news corpus, books, printed documents etc. Our test results showed that the recognition accuracy improved from 90.69\%, 54.34\% and 38.45 to 94.84\%, 71.15\% and 51.21\% respectively for high, medium and low quality images.},
	language = {en},
	number = {2,3},
	urldate = {2023-05-01},
	journal = {Advancement in Image Processing and Pattern Recognition},
	author = {Hengaju, Umesh and Bal, Dr Bal Krishna},
	month = jan,
	year = {2023},
	note = {Number: 2,3},
	pages = {40--52},
}
